# ğŸ  Analyse ImmobiliÃ¨re Tunisie (mubaweb.tn)

Un tableau de bord interactif pour analyser le marchÃ© immobilier tunisien Ã  partir de donnÃ©es collectÃ©es sur Mubawab.

## ğŸ“‹ Description du projet

Ce projet est une solution complÃ¨te pour l'analyse des annonces immobiliÃ¨res en Tunisie, composÃ©e de trois parties principales:

1. **Scraper** - Un script Python utilisant Selenium pour extraire les donnÃ©es des annonces immobiliÃ¨res (vente et location) depuis le site Mubawab.
2. **API** - Une API Flask permettant d'accÃ©der aux donnÃ©es collectÃ©es.
3. **Dashboard** - Un tableau de bord interactif construit avec Dash et Plotly pour visualiser et analyser les donnÃ©es du marchÃ© immobilier.

## ğŸš€ FonctionnalitÃ©s

- Extraction automatique des annonces immobiliÃ¨res
- Stockage des donnÃ©es au format Excel et dans une base de donnÃ©es SQLite
- API RESTful pour accÃ©der aux donnÃ©es
- Tableau de bord interactif avec:
  - Filtres dynamiques (par type de bien, ville, gamme de prix, etc.)
  - Visualisations diverses (rÃ©partition des types de biens, prix moyens, etc.)
  - Analyses comparatives (prix au mÂ², distribution des prix)
  - Top des annonces les plus chÃ¨res

## ğŸ”§ Installation

### PrÃ©requis

- Python 3.8+
- Chrome (pour le web scraping avec Selenium)

### Ã‰tapes d'installation

1. Clonez ce dÃ©pÃ´t:
```bash
git clone https://github.com/votre-username/analyse-immobiliere-tunisie.git
cd analyse-immobiliere-tunisie
```

2. CrÃ©ez un environnement virtuel:
```bash
python -m venv venv
```

3. Activez l'environnement virtuel:
   - Windows:
   ```bash
   venv\Scripts\activate
   ```
   - macOS/Linux:
   ```bash
   source venv/bin/activate
   ```

4. Installez les dÃ©pendances:
```bash
pip install -r requirements.txt
```

5. TÃ©lÃ©chargez ChromeDriver (si vous souhaitez exÃ©cuter le scraper):
   - Le script utilise webdriver_manager qui devrait tÃ©lÃ©charger automatiquement la version appropriÃ©e de ChromeDriver.

## ğŸ’» Utilisation

### Scraping des donnÃ©es

Pour collecter de nouvelles donnÃ©es depuis Mubawab:

```bash
python scrapping.py
```

Cela gÃ©nÃ©rera un fichier Excel `Mubawab_Annonces.xlsx` avec les donnÃ©es extraites.

### Lancement de l'API

Pour dÃ©marrer l'API Flask:

```bash
python app.py
```

L'API sera accessible Ã  l'adresse `http://localhost:8000`.

Endpoints disponibles:
- `GET /` - Page d'accueil de l'API
- `GET /annonces` - RÃ©cupÃ©rer toutes les annonces depuis la base de donnÃ©es
- `GET /annonces_csv` - RÃ©cupÃ©rer toutes les annonces depuis le fichier Excel
- `POST /scrape` - Lancer une nouvelle session de scraping en arriÃ¨re-plan

### Lancement du tableau de bord

Pour dÃ©marrer le tableau de bord Dash:

```bash
python dashboard.py
```

Le tableau de bord sera accessible Ã  l'adresse `http://localhost:8050`.

## ğŸ“Š Structure des donnÃ©es

Les donnÃ©es collectÃ©es incluent:
- Nature (vente/location)
- Titre de l'annonce
- Prix
- Localisation
- Superficie
- Nombre de piÃ¨ces
- Nombre de chambres
- Nombre de salles de bain
- Lien vers l'annonce

## ğŸ“ Structure du projet

```
/
â”œâ”€â”€ dashboard.py         # Application Dash pour le tableau de bord
â”œâ”€â”€ scrapping.py         # Script de scraping Selenium
â”œâ”€â”€ app.py               # API Flask
â”œâ”€â”€ requirements.txt     # DÃ©pendances Python
â”œâ”€â”€ annonces.db          # Base de donnÃ©es SQLite
â””â”€â”€ Mubawab_Annonces_Location_Vente.xlsx  # DonnÃ©es extraites
```

## ğŸ› ï¸ Technologies utilisÃ©es

- **Web Scraping**: Selenium, BeautifulSoup
- **Backend**: Flask, SQLite
- **Visualisation**: Dash, Plotly
- **Analyse de donnÃ©es**: Pandas, NumPy

## ğŸ“ Ã€ faire

- Ajouter une authentification Ã  l'API
- ImplÃ©menter une fonctionnalitÃ© d'alerte pour les nouvelles annonces
- AmÃ©liorer les analyses prÃ©dictives pour les prix immobiliers
- Ajouter la gÃ©olocalisation des biens sur une carte

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus d'informations.

## âš ï¸ Avertissement

Ce projet est crÃ©Ã© Ã  des fins Ã©ducatives et d'analyse. Respectez les conditions d'utilisation des sites web que vous scrapez et les rÃ©glementations concernant les donnÃ©es personnelles.
